import streamlit as st
import pandas as pd
import numpy as np
import io
import zipfile
from datetime import datetime, timedelta
import xlsxwriter

st.set_page_config(page_title="ì‹ ëª…ì•½í’ˆ ë°œì£¼ì„œ ìƒì„± ì‹œìŠ¤í…œ", layout="wide")

# ë¡œê³  ë° ì œëª©
col1, col2 = st.columns([1, 5])
with col1:
    st.image("ë¡œê³ ë¦¬ë‰´ì–¼.png", width=100)
with col2:
    st.title("ğŸ’Š ì‹ ëª…ì•½í’ˆ ë°œì£¼ì„œ ìƒì„± ì‹œìŠ¤í…œ")

st.markdown("ë§¤ì…ì²˜/ì œì¡°ì‚¬ë³„ ë°œì£¼ì„œë¥¼ ìë™ ìƒì„±í•˜ê³  Excel íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")

# ===== í‘œì¤€í™” í•¨ìˆ˜ =====
def normalize_columns(df, mapping):
    df.rename(columns={k: v for k, v in mapping.items() if k in df.columns}, inplace=True)
    return df

def check_required_columns(df, required, name):
    missing = [col for col in required if col not in df.columns]
    if missing:
        st.error(f"{name}ì— ë‹¤ìŒ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
        st.stop()

# ===== íŒŒì¼ ì—…ë¡œë“œ =====
st.sidebar.header("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
sales_file = st.sidebar.file_uploader("ë§¤ì¶œìë£Œ ì—…ë¡œë“œ", type=["xlsx"])
purchase_file = st.sidebar.file_uploader("ë§¤ì…ìë£Œ ì—…ë¡œë“œ", type=["xlsx"])
stock_file = st.sidebar.file_uploader("í˜„ì¬ê³  ì—…ë¡œë“œ", type=["xlsx"])

mode = st.sidebar.radio("ğŸ“… ë¶„ì„ ëª¨ë“œ ì„ íƒ", ["ìë™ ëª¨ë“œ (ìµœê·¼ 3ê°œì›”)", "ìˆ˜ë™ ëª¨ë“œ"])
group_by_option = st.sidebar.radio("ğŸ“‚ ê·¸ë£¹ ê¸°ì¤€", ["ë§¤ ì… ì²˜", "ì œ ì¡° ì‚¬"])

if sales_file and purchase_file and stock_file:
    # ===== ë°ì´í„° ì½ê¸° =====
    sales_df = pd.read_excel(sales_file)
    purchase_df = pd.read_excel(purchase_file)
    stock_df = pd.read_excel(stock_file)

    # ===== ì»¬ëŸ¼ í‘œì¤€í™” =====
    sales_df = normalize_columns(sales_df, {
        "ê±°ë˜ì¼ì": "ëª…ì„¸ì¼ì", "ì¼ì": "ëª…ì„¸ì¼ì",
        "ë§¤ì¶œì²˜": "ë§¤ ì¶œ ì²˜", "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…",
        "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„"
    })
    purchase_df = normalize_columns(purchase_df, {
        "ì…ê³ ì¼": "ì…ê³ ì¼ì", "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜",
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„",
        "ë§¤ì…ì²˜": "ë§¤ ì… ì²˜", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬",
        "ë‹¨ê°€": "ë§¤ì…ë‹¨ê°€", "ë§¤ì… ë‹¨ê°€": "ë§¤ì…ë‹¨ê°€"
    })
    stock_df = normalize_columns(stock_df, {
        "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜", "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…",
        "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬",
        "ì¬ê³ ": "ì¬ê³ ìˆ˜ëŸ‰"
    })

    # ===== í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬ =====
    check_required_columns(sales_df, ["ëª…ì„¸ì¼ì", "ë§¤ ì¶œ ì²˜", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ìˆ˜ëŸ‰", "ë§¤ì¶œë‹¨ê°€"], "ë§¤ì¶œìë£Œ")
    check_required_columns(purchase_df, ["ì…ê³ ì¼ì", "ë§¤ ì… ì²˜", "ìƒ í’ˆ ëª…", "ì œ ì¡° ì‚¬", "ìˆ˜ëŸ‰", "ë§¤ì…ë‹¨ê°€"], "ë§¤ì…ìë£Œ")
    check_required_columns(stock_df, ["ë§¤ ì… ì²˜", "ì œ ì¡° ì‚¬", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰"], "í˜„ì¬ê³ ")

    # ===== ë³‘í•© í‚¤ í‘œì¤€í™” (ê³µë°±, ëŒ€ì†Œë¬¸ì, íŠ¹ìˆ˜ë¬¸ì ì œê±°) =====
    for df in [sales_df, purchase_df, stock_df]:
        df["ìƒ í’ˆ ëª…"] = df["ìƒ í’ˆ ëª…"].astype(str).str.strip().str.upper().str.replace(" ", "", regex=False)
        df["í¬ì¥ë‹¨ìœ„"] = df["í¬ì¥ë‹¨ìœ„"].astype(str).str.strip().str.upper().str.replace(" ", "", regex=False)

    # ===== ë‚ ì§œ ë³€í™˜ =====
    sales_df["ëª…ì„¸ì¼ì"] = pd.to_datetime(sales_df["ëª…ì„¸ì¼ì"], errors="coerce")
    purchase_df["ì…ê³ ì¼ì"] = pd.to_datetime(purchase_df["ì…ê³ ì¼ì"], errors="coerce")

    # ===== ê¸°ê°„ í•„í„° =====
    if mode == "ìë™ ëª¨ë“œ (ìµœê·¼ 3ê°œì›”)":
        end_date = sales_df["ëª…ì„¸ì¼ì"].max()
        start_date = end_date - pd.DateOffset(months=3)
        filtered_sales = sales_df[(sales_df["ëª…ì„¸ì¼ì"] >= start_date) & (sales_df["ëª…ì„¸ì¼ì"] <= end_date)]
    else:
        start_date = st.sidebar.date_input("ì‹œì‘ì¼", value=sales_df["ëª…ì„¸ì¼ì"].min().date())
        end_date = st.sidebar.date_input("ì¢…ë£Œì¼", value=sales_df["ëª…ì„¸ì¼ì"].max().date())
        filtered_sales = sales_df[(sales_df["ëª…ì„¸ì¼ì"] >= pd.to_datetime(start_date)) &
                                  (sales_df["ëª…ì„¸ì¼ì"] <= pd.to_datetime(end_date))]

    # ===== ì „ì›” íŒë§¤ëŸ‰ ê³„ì‚° =====
    last_month_end = sales_df["ëª…ì„¸ì¼ì"].max().replace(day=1) - timedelta(days=1)
    last_month_start = last_month_end.replace(day=1)
    last_month_sales = sales_df[(sales_df["ëª…ì„¸ì¼ì"] >= last_month_start) &
                                (sales_df["ëª…ì„¸ì¼ì"] <= last_month_end)]
    last_month_qty = last_month_sales.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], as_index=False)["ìˆ˜ëŸ‰"].sum()
    last_month_qty.rename(columns={"ìˆ˜ëŸ‰": "ì „ì›”íŒë§¤ëŸ‰"}, inplace=True)

    # ===== ë³‘í•© ì „ ì¤‘ë³µ ì œê±° =====
    sales_df.drop_duplicates(subset=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ë§¤ ì¶œ ì²˜"], inplace=True)
    purchase_df.drop_duplicates(subset=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ë§¤ ì… ì²˜"], inplace=True)
    stock_df.drop_duplicates(subset=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ë§¤ ì… ì²˜"], inplace=True)

    # ===== ë³‘í•© =====
    purchase_df_merge = purchase_df[["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ë§¤ ì… ì²˜", "ì œ ì¡° ì‚¬", "ë§¤ì…ë‹¨ê°€"]].drop_duplicates()
    stock_df_merge = stock_df[["ë§¤ ì… ì²˜", "ì œ ì¡° ì‚¬", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰"]]

    merged = pd.merge(last_month_qty, stock_df_merge, on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")

    merged["ê³¼ì¬ê³ "] = (merged["ì¬ê³ ìˆ˜ëŸ‰"] - merged["ì „ì›”íŒë§¤ëŸ‰"]).apply(lambda x: x if x > 0 else 0)
    merged["ë¶€ì¡±ìˆ˜ëŸ‰"] = (merged["ì „ì›”íŒë§¤ëŸ‰"] - merged["ì¬ê³ ìˆ˜ëŸ‰"]).apply(lambda x: x if x > 0 else 0)
    merged["ë°œì£¼ìˆ˜ëŸ‰"] = merged["ë¶€ì¡±ìˆ˜ëŸ‰"]

    merged = pd.merge(merged, purchase_df_merge, on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")

    # ===== _x, _y ì»¬ëŸ¼ ì •ë¦¬ =====
    if "ë§¤ ì… ì²˜_x" in merged.columns:
        merged.drop(columns=["ë§¤ ì… ì²˜_y"], inplace=True, errors="ignore")
        merged.rename(columns={"ë§¤ ì… ì²˜_x": "ë§¤ ì… ì²˜"}, inplace=True)
    if "ì œ ì¡° ì‚¬_x" in merged.columns:
        merged.drop(columns=["ì œ ì¡° ì‚¬_y"], inplace=True, errors="ignore")
        merged.rename(columns={"ì œ ì¡° ì‚¬_x": "ì œ ì¡° ì‚¬"}, inplace=True)

    merged = pd.merge(merged,
                      sales_df[["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ë§¤ì¶œë‹¨ê°€"]].drop_duplicates(),
                      on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")

    merged["ë§¤ì…ë‹¨ê°€"] = merged["ë§¤ì…ë‹¨ê°€"].fillna(0)
    merged["í•©ê³„ê¸ˆì•¡"] = merged["ë°œì£¼ìˆ˜ëŸ‰"] * merged["ë§¤ì…ë‹¨ê°€"]

    # ===== ë§ˆì§„ìœ¨ ì œê±° =====
    if "ë§ˆì§„ìœ¨" in merged.columns:
        merged.drop(columns=["ë§ˆì§„ìœ¨"], inplace=True, errors="ignore")

    # ===== ë³‘í•© í›„ ì¤‘ë³µ ì œê±° (ê°™ì€ ì œí’ˆì€ í•œ ì¤„ë¡œ í•©ì¹¨) =====
    merged = merged.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ë§¤ ì… ì²˜", "ì œ ì¡° ì‚¬"], as_index=False).agg({
        "ì „ì›”íŒë§¤ëŸ‰": "sum",
        "ì¬ê³ ìˆ˜ëŸ‰": "sum",
        "ê³¼ì¬ê³ ": "sum",
        "ë¶€ì¡±ìˆ˜ëŸ‰": "sum",
        "ë°œì£¼ìˆ˜ëŸ‰": "sum",
        "ë§¤ì…ë‹¨ê°€": "first",
        "ë§¤ì¶œë‹¨ê°€": "first",
        "í•©ê³„ê¸ˆì•¡": "sum"
    })

    # ===== ê·¸ë£¹ ì»¬ëŸ¼ ë³´ì • =====
    if group_by_option not in merged.columns:
        merged[group_by_option] = "ê¸°íƒ€"

    # ===== ë¯¸ë¦¬ë³´ê¸° =====
    if not merged.empty:
        st.subheader("ğŸ“Š ë°œì£¼ì„œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(merged)
    else:
        st.warning("âš  ë°œì£¼ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ===== ë°œì£¼ì„œ ZIP ë‹¤ìš´ë¡œë“œ =====
    if st.button("ğŸ“¦ ë°œì£¼ì„œ ZIP ë‹¤ìš´ë¡œë“œ"):
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, "w") as zipf:
            for key, group in merged.groupby(group_by_option):
                file_key = str(key).strip() if pd.notna(key) and str(key).strip() else "ê¸°íƒ€"
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                    group.to_excel(writer, index=False, sheet_name="ë°œì£¼ì„œ")
                    workbook = writer.book
                    worksheet = writer.sheets["ë°œì£¼ì„œ"]

                    # ===== ì„œì‹ =====
                    header_fmt = workbook.add_format({"bold": True, "bg_color": "#DCE6F1",
                                                      "align": "center", "valign": "vcenter", "border": 1})
                    cell_fmt = workbook.add_format({"align": "center", "valign": "vcenter", "border": 1})
                    num_fmt = workbook.add_format({"align": "right", "valign": "vcenter",
                                                   "border": 1, "num_format": "#,##0"})

                    # í—¤ë” ì‘ì„±
                    for col_num, value in enumerate(group.columns.values):
                        worksheet.write(0, col_num, value, header_fmt)

                    # ë°ì´í„° ì‘ì„±
                    for row_num, row_data in enumerate(group.values, start=1):
                        for col_num, cell_value in enumerate(row_data):
                            if pd.isna(cell_value):
                                worksheet.write(row_num, col_num, "", cell_fmt)
                            elif isinstance(cell_value, (int, float, np.number)):
                                worksheet.write_number(row_num, col_num, float(cell_value), num_fmt)
                            else:
                                worksheet.write(row_num, col_num, str(cell_value), cell_fmt)

                    # ì—´ ë„ˆë¹„ ìë™
                    for i, col in enumerate(group.columns):
                        col_width = max(len(str(col)), max(group[col].astype(str).map(len))) + 2
                        worksheet.set_column(i, i, col_width)

                zipf.writestr(f"{file_key} ë°œì£¼ì„œ.xlsx", output.getvalue())

        zip_buffer.seek(0)
        st.download_button("ğŸ“¥ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=zip_buffer,
                           file_name="ë°œì£¼ì„œ_ì—‘ì…€.zip", mime="application/zip")

else:
    st.warning("ğŸ“‚ ë§¤ì¶œ, ë§¤ì…, í˜„ì¬ê³  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
